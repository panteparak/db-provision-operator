name: CI

on:
  push:
    branches: [main]
    tags: ['v*']
  pull_request:
    branches: [main]

env:
  GO_VERSION_FILE: go.mod
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # ============================================================================
  # Stage 0: Setup (Define shared configuration)
  # ============================================================================

  # Define platforms matrix in one place - used by docker-build and security-scan
  setup:
    name: Setup
    runs-on: ubuntu-latest
    outputs:
      platforms: ${{ steps.platforms.outputs.matrix }}
    steps:
      - name: Define platform matrix
        id: platforms
        run: |
          # Define platforms here - single source of truth
          # Add new platforms by adding objects to the array
          PLATFORMS='[
            {"platform": "linux/amd64", "runner": "ubuntu-latest", "required": true}
          ]'
          # Uncomment to add ARM64 support (builds are slow due to QEMU emulation):
          # PLATFORMS='[
          #   {"platform": "linux/amd64", "runner": "ubuntu-latest", "required": true},
          #   {"platform": "linux/arm64", "runner": "ubuntu-latest", "required": false}
          # ]'

          # Output as JSON for matrix strategy
          echo "matrix=$(echo $PLATFORMS | jq -c .)" >> $GITHUB_OUTPUT

  # ============================================================================
  # Stage 1: Parallel Jobs (Lint, Unit Tests, Docker Build, Docs)
  # ============================================================================

  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: ${{ env.GO_VERSION_FILE }}
          cache: true  # Enable Go module caching

      - name: Run golangci-lint
        uses: golangci/golangci-lint-action@v8
        with:
          version: v2.1.0

  unit-test:
    name: Unit Tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: ${{ env.GO_VERSION_FILE }}
          cache: true  # Enable Go module caching

      - name: Run unit tests
        run: make test

      - name: Upload coverage report
        uses: codecov/codecov-action@v4
        with:
          files: cover.out
          fail_ci_if_error: false
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

  envtest:
    name: Controller Tests (envtest)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: ${{ env.GO_VERSION_FILE }}
          cache: true

      # Derive K8S version from go.mod (same logic as Makefile)
      - name: Get envtest K8S version
        id: envtest-version
        run: |
          K8S_VERSION=$(go list -m -f "{{ .Version }}" k8s.io/api | awk -F'[v.]' '{printf "1.%d", $3}')
          echo "version=$K8S_VERSION" >> $GITHUB_OUTPUT
          echo "Using Kubernetes version: $K8S_VERSION"

      # Cache envtest binaries (~100MB) to speed up CI
      - name: Cache envtest binaries
        uses: actions/cache@v4
        with:
          path: bin/k8s
          key: envtest-${{ runner.os }}-k8s-${{ steps.envtest-version.outputs.version }}
          restore-keys: |
            envtest-${{ runner.os }}-k8s-

      - name: Run envtest-based controller tests
        run: make test-envtest

      - name: Upload coverage report
        uses: codecov/codecov-action@v4
        with:
          files: cover-envtest.out
          flags: envtest
          fail_ci_if_error: false
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

  template-comparison:
    name: Template Comparison
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: ${{ env.GO_VERSION_FILE }}
          cache: true

      - name: Install Helm
        uses: azure/setup-helm@v4
        with:
          version: v3.14.0

      - name: Install Kustomize
        run: |
          curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh" | bash
          sudo mv kustomize /usr/local/bin/

      - name: Copy dashboards for templates
        run: make copy-dashboards

      - name: Run Template Comparison
        run: make test-templates

  integration-test:
    name: Integration Tests (${{ matrix.database }})
    runs-on: ubuntu-latest
    needs: [gate]
    strategy:
      fail-fast: false
      matrix:
        database: [postgresql, mysql, mariadb, cockroachdb]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: ${{ env.GO_VERSION_FILE }}
          cache: true  # Enable Go module caching

      # Derive K8S version from go.mod (same logic as Makefile)
      - name: Get envtest K8S version
        id: envtest-version
        run: |
          K8S_VERSION=$(go list -m -f "{{ .Version }}" k8s.io/api | awk -F'[v.]' '{printf "1.%d", $3}')
          echo "version=$K8S_VERSION" >> $GITHUB_OUTPUT
          echo "Using Kubernetes version: $K8S_VERSION"

      # Cache envtest binaries (~100MB) to speed up CI
      - name: Cache envtest binaries
        uses: actions/cache@v4
        with:
          path: bin/k8s
          key: envtest-${{ runner.os }}-k8s-${{ steps.envtest-version.outputs.version }}
          restore-keys: |
            envtest-${{ runner.os }}-k8s-

      # testcontainers-go manages Docker containers programmatically
      # No manual container setup needed - tests handle their own lifecycle
      - name: Run integration tests
        env:
          INTEGRATION_TEST_DATABASE: ${{ matrix.database }}
          # testcontainers-go will automatically start and configure containers
          TESTCONTAINERS_RYUK_DISABLED: false
        run: make test-integration

      - name: Upload test reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-reports-${{ matrix.database }}
          path: test-reports/
          retention-days: 30
          if-no-files-found: ignore

      - name: Upload integration coverage report
        uses: codecov/codecov-action@v4
        with:
          files: cover-integration.out
          flags: integration-${{ matrix.database }}
          fail_ci_if_error: false
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

  # Build each platform in parallel using shared matrix from setup job
  docker-build:
    name: Docker Build (${{ matrix.config.platform }})
    runs-on: ${{ matrix.config.runner }}
    needs: [setup]
    permissions:
      contents: read
      packages: write
    strategy:
      fail-fast: false
      matrix:
        config: ${{ fromJSON(needs.setup.outputs.platforms) }}
    # Continue on error for optional platforms (ARM64 when enabled)
    continue-on-error: ${{ !matrix.config.required }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Get short SHA
        id: short-sha
        run: echo "sha=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT

      - name: Prepare platform pair
        id: platform
        run: |
          platform=${{ matrix.config.platform }}
          echo "pair=${platform//\//-}" >> $GITHUB_OUTPUT

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # Login for push events (full access) and PRs (read-only for cache)
      # PRs need read access to pull registry cache from main branch
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata (tags, labels)
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}

      - name: Build and push by digest
        id: build
        if: github.event_name != 'pull_request'
        uses: docker/build-push-action@v6
        with:
          context: .
          platforms: ${{ matrix.config.platform }}
          labels: ${{ steps.meta.outputs.labels }}
          outputs: type=image,name=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }},push-by-digest=true,name-canonical=true,push=true
          # Multi-layer cache strategy:
          # 1. GHA cache (fast, per-platform, workflow-local)
          # 2. Registry cache (persistent fallback when GHA cache is evicted)
          cache-from: |
            type=gha,scope=build-${{ steps.platform.outputs.pair }}
            type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache-${{ steps.platform.outputs.pair }}
          cache-to: |
            type=gha,scope=build-${{ steps.platform.outputs.pair }},mode=max
            type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache-${{ steps.platform.outputs.pair }},mode=max,compression=zstd,oci-mediatypes=true

      - name: Export digest
        if: github.event_name != 'pull_request'
        run: |
          mkdir -p /tmp/digests
          digest="${{ steps.build.outputs.digest }}"
          touch "/tmp/digests/${digest#sha256:}"

      - name: Upload digest
        if: github.event_name != 'pull_request'
        uses: actions/upload-artifact@v4
        with:
          name: digests-${{ steps.platform.outputs.pair }}
          path: /tmp/digests/*
          if-no-files-found: error
          retention-days: 1

      # For PRs, only build amd64 and export for E2E tests
      - name: Build image for PR (local)
        if: github.event_name == 'pull_request' && matrix.config.platform == 'linux/amd64'
        uses: docker/build-push-action@v6
        with:
          context: .
          platforms: linux/amd64
          push: false
          load: true
          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:sha-${{ steps.short-sha.outputs.sha }}
          # For PRs: Use registry cache from main branch as primary source
          # This enables cache sharing between main branch and PRs
          cache-from: |
            type=gha,scope=build-linux-amd64
            type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache-linux-amd64
          cache-to: type=gha,scope=build-linux-amd64,mode=max

      - name: Save image for PR
        if: github.event_name == 'pull_request' && matrix.config.platform == 'linux/amd64'
        run: |
          docker save ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:sha-${{ steps.short-sha.outputs.sha }} \
            -o /tmp/operator-image.tar

      - name: Upload image artifact for PR
        if: github.event_name == 'pull_request' && matrix.config.platform == 'linux/amd64'
        uses: actions/upload-artifact@v4
        with:
          name: operator-image
          path: /tmp/operator-image.tar
          retention-days: 1

  # Merge platform images into multi-arch manifest
  docker-merge:
    name: Docker Merge Manifests
    runs-on: ubuntu-latest
    if: github.event_name != 'pull_request'
    needs: [docker-build]
    permissions:
      contents: read
      packages: write
    outputs:
      image-sha: sha-${{ steps.short-sha.outputs.sha }}
    steps:
      - name: Get short SHA
        id: short-sha
        # Use GITHUB_SHA instead of git - no checkout needed
        run: echo "sha=${GITHUB_SHA:0:7}" >> $GITHUB_OUTPUT

      - name: Download digests
        uses: actions/download-artifact@v4
        with:
          path: /tmp/digests
          pattern: digests-*
          merge-multiple: true

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata (tags, labels)
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            # Set latest tag for main branch
            type=raw,value=latest,enable=${{ github.ref == 'refs/heads/main' }}
            # Tag with commit SHA (sha-<short-sha>)
            type=sha,prefix=sha-,format=short
            # Tag with branch name
            type=ref,event=branch
            # Tag with PR number
            type=ref,event=pr
            # Tag with semver (v1.0.0 -> 1.0.0, latest)
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=semver,pattern={{major}},enable=${{ !startsWith(github.ref, 'refs/tags/v0.') }}

      - name: Create manifest list and push
        working-directory: /tmp/digests
        run: |
          docker buildx imagetools create $(jq -cr '.tags | map("-t " + .) | join(" ")' <<< "$DOCKER_METADATA_OUTPUT_JSON") \
            $(printf '${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}@sha256:%s ' *)

      - name: Inspect image
        run: |
          docker buildx imagetools inspect ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ steps.meta.outputs.version }}

      - name: Generate SBOM
        uses: anchore/sbom-action@v0
        with:
          image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:sha-${{ steps.short-sha.outputs.sha }}
          format: spdx-json
          output-file: sbom.spdx.json

      - name: Upload SBOM
        uses: actions/upload-artifact@v4
        with:
          name: sbom
          path: sbom.spdx.json

  # Trivy security scanning - scans each platform using shared matrix
  security-scan:
    name: Security Scan (${{ matrix.config.platform }})
    runs-on: ubuntu-latest
    needs: [setup, docker-merge]
    if: github.event_name != 'pull_request'
    permissions:
      contents: read
      security-events: write  # For uploading SARIF to GitHub Security tab
    strategy:
      fail-fast: false
      matrix:
        config: ${{ fromJSON(needs.setup.outputs.platforms) }}
    steps:
      - name: Prepare platform pair
        id: platform
        run: |
          platform=${{ matrix.config.platform }}
          echo "pair=${platform//\//-}" >> $GITHUB_OUTPUT

      # Download the digest for this specific platform
      - name: Download digest
        uses: actions/download-artifact@v4
        with:
          name: digests-${{ steps.platform.outputs.pair }}
          path: /tmp/digests

      - name: Get image digest
        id: digest
        run: |
          DIGEST=$(ls /tmp/digests)
          echo "digest=sha256:$DIGEST" >> $GITHUB_OUTPUT
          echo "Image digest for ${{ matrix.config.platform }}: sha256:$DIGEST"

      # Generate SBOM from image (scans the image once)
      - name: Generate SBOM
        uses: aquasecurity/trivy-action@0.28.0
        with:
          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}@${{ steps.digest.outputs.digest }}
          scan-type: 'image'
          format: 'cyclonedx'
          output: 'sbom-${{ steps.platform.outputs.pair }}.cyclonedx.json'

      # Scan SBOM for vulnerabilities - JSON output (all severities)
      - name: Scan SBOM for vulnerabilities (JSON)
        uses: aquasecurity/trivy-action@0.28.0
        with:
          scan-type: 'sbom'
          scan-ref: 'sbom-${{ steps.platform.outputs.pair }}.cyclonedx.json'
          format: 'json'
          output: 'trivy-results-${{ steps.platform.outputs.pair }}.json'

      # Scan SBOM for vulnerabilities - Table output (MEDIUM+, ignore unfixed)
      - name: Scan SBOM for vulnerabilities (Table)
        uses: aquasecurity/trivy-action@0.28.0
        with:
          scan-type: 'sbom'
          scan-ref: 'sbom-${{ steps.platform.outputs.pair }}.cyclonedx.json'
          format: 'table'
          output: 'trivy-report-${{ steps.platform.outputs.pair }}.txt'
          severity: 'MEDIUM,HIGH,CRITICAL'
          ignore-unfixed: true

      # Scan SBOM for SARIF output (GitHub Security tab)
      - name: Scan SBOM for SARIF report
        uses: aquasecurity/trivy-action@0.28.0
        with:
          scan-type: 'sbom'
          scan-ref: 'sbom-${{ steps.platform.outputs.pair }}.cyclonedx.json'
          format: 'sarif'
          output: 'trivy-results-${{ steps.platform.outputs.pair }}.sarif'

      - name: Upload SARIF file
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results-${{ steps.platform.outputs.pair }}.sarif'
          category: 'trivy-${{ steps.platform.outputs.pair }}'

      # Upload all security scan artifacts for this platform
      - name: Upload security scan artifacts
        uses: actions/upload-artifact@v4
        with:
          name: security-scan-${{ steps.platform.outputs.pair }}
          path: |
            sbom-${{ steps.platform.outputs.pair }}.cyclonedx.json
            trivy-results-${{ steps.platform.outputs.pair }}.json
            trivy-report-${{ steps.platform.outputs.pair }}.txt
            trivy-results-${{ steps.platform.outputs.pair }}.sarif
          retention-days: 30

  manifests:
    name: Verify Manifests
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          # Use a token with write access for auto-commit
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: ${{ env.GO_VERSION_FILE }}
          cache: true  # Enable Go module caching

      - name: Generate manifests
        run: make manifests

      - name: Check for uncommitted changes
        id: check-changes
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "has_changes=true" >> $GITHUB_OUTPUT
            echo "Generated manifests are out of date:"
            git diff
          else
            echo "has_changes=false" >> $GITHUB_OUTPUT
            echo "Manifests are up to date"
          fi

      # Auto-commit on push to main branch
      - name: Auto-commit manifests
        if: steps.check-changes.outputs.has_changes == 'true' && github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          git commit -m "chore: auto-generate manifests [skip ci]

          Co-Authored-By: github-actions[bot] <github-actions[bot]@users.noreply.github.com>"
          git push

      # Fail on PRs if manifests are out of date (developer needs to run make manifests locally)
      - name: Fail if manifests out of date (PR)
        if: steps.check-changes.outputs.has_changes == 'true' && github.event_name == 'pull_request'
        run: |
          echo "::error::Generated manifests are out of date. Run 'make manifests' and commit the changes."
          exit 1

      - name: Install Helm
        uses: azure/setup-helm@v4
        with:
          version: 'v3.14.0'

      - name: Copy dashboards for Helm/Kustomize
        run: make copy-dashboards

      - name: Lint Helm chart
        run: helm lint charts/db-provision-operator

      - name: Test Helm chart template
        run: |
          helm template test-release charts/db-provision-operator \
            --set image.tag=test \
            --debug > /dev/null

      - name: Test Helm chart with Grafana dashboards enabled
        run: |
          helm template test-release charts/db-provision-operator \
            --set image.tag=test \
            --set grafanaDashboards.enabled=true \
            --debug > /dev/null

      # Validate rendered YAML for duplicate keys (helm template doesn't catch this)
      - name: Validate Helm template YAML (strict)
        run: |
          validate_helm_yaml() {
            python3 -c "
          import sys, yaml
          from yaml import SafeLoader

          def no_duplicates_constructor(loader, node, deep=False):
              mapping = {}
              for key_node, value_node in node.value:
                  key = loader.construct_object(key_node, deep=deep)
                  if key in mapping:
                      raise yaml.constructor.ConstructorError(
                          'while constructing a mapping', node.start_mark,
                          f'found duplicate key \"{key}\"', key_node.start_mark
                      )
                  mapping[key] = loader.construct_object(value_node, deep=deep)
              return mapping

          SafeLoader.add_constructor(yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG, no_duplicates_constructor)

          try:
              list(yaml.safe_load_all(sys.stdin))
          except Exception as e:
              print(f'âœ— Validation failed: {e}', file=sys.stderr)
              sys.exit(1)
          "
          }

          echo "Testing default values..."
          helm template test charts/db-provision-operator --set image.tag=test | validate_helm_yaml
          echo "âœ“ Default values OK"

          echo "Testing with custom replica count..."
          helm template test charts/db-provision-operator \
            --set image.tag=test \
            --set replicaCount=2 | validate_helm_yaml
          echo "âœ“ Custom replica count OK"

          echo "Testing with Grafana dashboards enabled..."
          helm template test charts/db-provision-operator \
            --set image.tag=test \
            --set grafanaDashboards.enabled=true | validate_helm_yaml
          echo "âœ“ Grafana dashboards OK"

          echo "All Helm template validations passed!"

  generate:
    name: Verify Generated Code
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: ${{ env.GO_VERSION_FILE }}
          cache: true  # Enable Go module caching

      - name: Generate code
        run: make generate

      - name: Check for uncommitted changes
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "Error: Generated code is out of date. Run 'make generate' and commit the changes."
            git diff
            exit 1
          fi

  docs:
    name: Docs Build
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip
          cache-dependency-path: docs/requirements.txt

      - name: Install dependencies
        run: pip install -r docs/requirements.txt

      - name: Build docs
        run: mkdocs build --strict

  # ============================================================================
  # Stage 2: Gate (Wait for all parallel jobs)
  # ============================================================================

  gate:
    name: Gate
    runs-on: ubuntu-latest
    # For push: wait for docker-merge (multi-arch manifest)
    # For PR: docker-merge is skipped, so we only check docker-build
    needs: [setup, lint, unit-test, envtest, template-comparison, docker-build, docker-merge, manifests, generate, docs]
    if: always()
    steps:
      - name: Check job results
        run: |
          echo "Job results:"
          echo "  setup: ${{ needs.setup.result }}"
          echo "  lint: ${{ needs.lint.result }}"
          echo "  unit-test: ${{ needs.unit-test.result }}"
          echo "  envtest: ${{ needs.envtest.result }}"
          echo "  template-comparison: ${{ needs.template-comparison.result }}"
          echo "  docker-build: ${{ needs.docker-build.result }}"
          echo "  docker-merge: ${{ needs.docker-merge.result }}"
          echo "  manifests: ${{ needs.manifests.result }}"
          echo "  generate: ${{ needs.generate.result }}"
          echo "  docs: ${{ needs.docs.result }}"

          # Check required jobs (must be success)
          FAILED=""
          [[ "${{ needs.setup.result }}" != "success" ]] && FAILED="${FAILED} setup"
          [[ "${{ needs.lint.result }}" != "success" ]] && FAILED="${FAILED} lint"
          [[ "${{ needs.unit-test.result }}" != "success" ]] && FAILED="${FAILED} unit-test"
          [[ "${{ needs.envtest.result }}" != "success" ]] && FAILED="${FAILED} envtest"
          [[ "${{ needs.template-comparison.result }}" != "success" ]] && FAILED="${FAILED} template-comparison"
          [[ "${{ needs.docker-build.result }}" != "success" ]] && FAILED="${FAILED} docker-build"
          [[ "${{ needs.manifests.result }}" != "success" ]] && FAILED="${FAILED} manifests"
          [[ "${{ needs.generate.result }}" != "success" ]] && FAILED="${FAILED} generate"
          [[ "${{ needs.docs.result }}" != "success" ]] && FAILED="${FAILED} docs"

          # docker-merge is only required for push events (skipped for PRs)
          if [[ "${{ github.event_name }}" != "pull_request" ]]; then
            [[ "${{ needs.docker-merge.result }}" != "success" ]] && FAILED="${FAILED} docker-merge"
          fi

          if [[ -n "$FAILED" ]]; then
            echo "::error::Failed jobs:$FAILED"
            exit 1
          fi

          echo "All required checks passed successfully"

  # ============================================================================
  # Stage 3: Integration Tests (after Gate passes)
  # ============================================================================

  # Note: integration-test job is defined above but runs here after gate

  # ============================================================================
  # Stage 4: E2E Tests (Docker Compose + k3d + Helm)
  # Uses same Makefile micro-steps as local development for consistency
  # ============================================================================

  e2e:
    name: E2E (${{ matrix.database }})
    runs-on: ubuntu-latest
    needs: [integration-test]
    strategy:
      fail-fast: false
      max-parallel: 4  # Run all 4 database tests in parallel
      matrix:
        database: [postgresql, mysql, mariadb, cockroachdb]
        include:
          - database: postgresql
            port: 5432
          - database: mysql
            port: 3306
          - database: mariadb
            port: 3307
          - database: cockroachdb
            port: 26257

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: go.mod
          cache: true

      - name: Get short SHA
        id: short-sha
        run: echo "sha=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT

      - name: Install k3d
        run: curl -s https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash

      # Start only the required database via Docker Compose (Makefile micro-step)
      - name: Start database
        run: make e2e-db-up E2E_DATABASE=${{ matrix.database }}

      # Create k3d cluster (Makefile micro-step)
      - name: Create k3d cluster
        run: make e2e-cluster-create

      # For push events: Pull operator image from registry
      - name: Pull operator image from registry
        if: github.event_name != 'pull_request'
        run: |
          docker pull ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:sha-${{ steps.short-sha.outputs.sha }}

      # For PRs: Download and load operator image from artifact
      - name: Download operator image artifact
        if: github.event_name == 'pull_request'
        uses: actions/download-artifact@v4
        with:
          name: operator-image
          path: /tmp

      - name: Load operator image for PR
        if: github.event_name == 'pull_request'
        run: docker load -i /tmp/operator-image.tar

      # Load operator image into k3d (Makefile micro-step with custom image)
      - name: Load operator image into k3d
        run: make e2e-image-load E2E_IMG=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:sha-${{ steps.short-sha.outputs.sha }}

      # Install CRDs (Makefile micro-step)
      - name: Install CRDs
        run: make e2e-install-crds

      # Deploy operator via Helm (intentionally uses Helm, not Kustomize)
      - name: Install Helm
        uses: azure/setup-helm@v4
        with:
          version: 'v3.14.0'

      - name: Deploy operator (Helm)
        run: |
          helm install db-provision-operator ./charts/db-provision-operator \
            --namespace db-provision-operator-system \
            --create-namespace \
            --set image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} \
            --set image.tag=sha-${{ steps.short-sha.outputs.sha }} \
            --set image.pullPolicy=IfNotPresent \
            --wait \
            --timeout 5m

      - name: Wait for operator ready
        run: |
          kubectl wait --for=condition=Available \
            deployment -l app.kubernetes.io/name=db-provision-operator \
            -n db-provision-operator-system \
            --timeout=120s

      # Create DatabaseInstance pointing to Docker host (Makefile micro-step)
      - name: Create DatabaseInstance
        run: make e2e-create-db-instance E2E_DATABASE=${{ matrix.database }}

      # Run E2E tests (Makefile micro-step)
      - name: Run E2E tests
        env:
          E2E_DELETION_TIMEOUT: "120s"
        run: make e2e-local-run-tests E2E_DATABASE=${{ matrix.database }}

      - name: Collect logs on failure
        if: failure()
        run: |
          echo "=== OPERATOR LOGS ===" && kubectl logs -n db-provision-operator-system -l control-plane=controller-manager --tail=500 || true
          echo "=== OPERATOR POD ===" && kubectl describe pods -n db-provision-operator-system -l control-plane=controller-manager || true
          echo "=== DATABASE CONTAINERS ===" && docker compose -f docker-compose.e2e.yml logs --tail=100 || true
          echo "=== CRs ===" && kubectl get databaseinstances,databases,databaseusers,databaseroles,databasegrants -A -o yaml || true
          echo "=== EVENTS ===" && kubectl get events -A --sort-by='.lastTimestamp' | tail -100 || true
          echo "=== PODS ===" && kubectl get pods -A || true

      # Cleanup (Makefile micro-step)
      - name: Cleanup
        if: always()
        run: make e2e-local-cleanup

  # ============================================================================
  # Stage 5: CI Success
  # ============================================================================

  ci-success:
    name: CI Success
    runs-on: ubuntu-latest
    needs: [e2e]
    steps:
      - name: CI pipeline completed
        run: |
          echo "ðŸŽ‰ All CI checks and E2E tests passed!"
          echo ""
          echo "Pipeline summary:"
          echo "  âœ… Lint"
          echo "  âœ… Unit Tests (fast, no envtest)"
          echo "  âœ… Controller Tests (envtest)"
          echo "  âœ… Template Comparison (Helm â‰¡ Kustomize)"
          echo "  âœ… Docker Build"
          echo "  âœ… Manifests Verification"
          echo "  âœ… Generated Code Verification"
          echo "  âœ… Docs Build"
          echo "  âœ… Integration Tests (PostgreSQL)"
          echo "  âœ… Integration Tests (MySQL)"
          echo "  âœ… Integration Tests (MariaDB)"
          echo "  âœ… Integration Tests (CockroachDB)"
          echo "  âœ… E2E Tests (PostgreSQL)"
          echo "  âœ… E2E Tests (MySQL)"
          echo "  âœ… E2E Tests (MariaDB)"
          echo "  âœ… E2E Tests (CockroachDB)"
